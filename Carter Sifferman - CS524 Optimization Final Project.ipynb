{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carter Sifferman - CS524 Final Project: Geometric Calibration of a Sensor Attached to a Robot Arm\n",
    "\n",
    "## Instructions for running the notebook yourself\n",
    "Activate the virtual environment: `source environments/gmsjupyter/bin/activate`\n",
    "\n",
    "Start the jupyter notebook: `jupyter notebook`\n",
    "\n",
    "Developed with GAMS 36.2, python 3.8.10, jupyter 4.6.3\n",
    "\n",
    "# Problem Introduction\n",
    "\n",
    "This project is related to a research project that I've been doing with Professors Mike Gleicher and Mohit Gupta.\n",
    "\n",
    "Say you have a robot arm like the one shown below\n",
    "\n",
    "<img src=\"ur5.jpeg\" width=300 height=300 />\n",
    "\n",
    "Question is: how should we solve this to deal with uncertainty / noise\n",
    "\n",
    "Since we only need to do this once per sensor and it takes a while to move the robot anyway, speed is not crucial. Accuracy, precision, and robustness to noise are much more important. \n",
    "\n",
    "# Approach\n",
    "\n",
    "# Formulation\n",
    "\n",
    "<img src=\"teaser.jpg\" width=600/>\n",
    "\n",
    "$(\\textbf{a} \\cdot \\textbf{A}_i\\textbf{p}) + \\textbf{a} \\cdot (d_i*\\textbf{A}_i\\textbf{u}) = -c-\\textbf{a}\\textbf{t}_i$\n",
    "\n",
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Simulated Data\n",
    "\n",
    "Before building a model, it will be helpful to generate some simulated data. While we could jump straight into using real-world data from a real robot arm with a sensor attached, using simulated data will let us test our model under \"ideal\" conditions with no noise. After we confirm that our model works under ideal conditions, we can test it out on real data (see section [Evaluation](#evaluation) below).\n",
    "\n",
    "In the cell below, we define some helper functions that will help us create simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_observation(p, u, a, d, epsilon=1e-6):\n",
    "    \"\"\"Generate an observation from a point looking at a plane.\n",
    "\n",
    "    Generates an observation (distance and observation point) for a sensor at\n",
    "    location p looking in the direction given by the vector u looking at the\n",
    "    plane defined by a[0]x + a[1]y + a[2]z + d = 0.\n",
    "\n",
    "    https://rosettacode.org/wiki/Find_the_intersection_of_a_line_with_a_plane#Python\n",
    "\n",
    "    Args:\n",
    "        p (3-tuple of floats): the position of the sensor (x, y, z).\n",
    "        u (3-tuple of floats): the orientation of the sensor (x, y, z).\n",
    "          Does not have to be a unit vector.\n",
    "        a (3-tuple of floats): the equation for the line where a[0]x + a[1]y + a[2]z + d = 0.\n",
    "        d (float) the d portion of the line equation.\n",
    "\n",
    "    Returns:\n",
    "        The distance and intersection point as a tuple, for example, with distance\n",
    "        5.2 and intersection point (8.1, 0.3, 4):\n",
    "\n",
    "        (5.2, (8.1, 0.3, 4)) or float('inf') if the sensor does not see the plane.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: The line is undefined.\n",
    "    \"\"\"\n",
    "    a = np.array(a)\n",
    "    p = np.array(p)\n",
    "    u = np.array(u)\n",
    "\n",
    "    if(a[0] != 0):\n",
    "        plane_point = np.array([-d/a[0], 0, 0])\n",
    "    elif(a[1] != 0):\n",
    "        plane_point = np.array([0, -d/a[1], 0])\n",
    "    elif(a[2] != 0):\n",
    "        plane_point = np.array([0, 0, -d/a[2]])\n",
    "    else:\n",
    "        raise ValueError(\"The plane with normal a=[0,0,0] is undefined\")\n",
    "\n",
    "    ndotu = a.dot(u)\n",
    "    if abs(ndotu) < epsilon:\n",
    "        return float('inf')\n",
    "\n",
    "    w = p - plane_point\n",
    "    si = -a.dot(w) / ndotu\n",
    "    Psi = w + si * u + plane_point\n",
    "    \n",
    "    dist = np.linalg.norm(Psi - p)\n",
    "\n",
    "    if(np.allclose((dist * u) + p, Psi)):\n",
    "        return (dist, Psi)\n",
    "    else:\n",
    "        return float('inf')\n",
    "\n",
    "def gen_sim_trial(transforms, p, u, a, d):\n",
    "    \"\"\"Generate multiple observations of the same sensor pose looking at the same plane\n",
    "    \n",
    "    Args:\n",
    "        transforms (list of 4x4 np.arrays): list of transforms to representing motions of\n",
    "          the section of the robot which the sensor is attached to. Represented in homogenous\n",
    "          coordinates. Should be rigid.\n",
    "        p (3-tuple of floats): the position of the sensor (x, y, z).\n",
    "        u (3-tuple of floats): the orientation of the sensor (x, y, z).\n",
    "        a (3-tuple of floats): the equation for the line where a[0]x + a[1]y + a[2]z + d = 0.\n",
    "        d (float) the d portion of the line equation.\n",
    "        \n",
    "    Returns:\n",
    "        (list) simulated distance measurements\n",
    "    \"\"\"\n",
    "    \n",
    "    distances = []\n",
    "    for tf in transforms:\n",
    "        # apply transform to p and u\n",
    "        tf_p = (tf @ np.array(list(p) + [1]))[:3]\n",
    "        tf_u = (tf @ np.array(list(u) + [0]))[:3]\n",
    "        \n",
    "        distances.append(gen_observation(tf_p, tf_u, a, d)[0])\n",
    "        \n",
    "    return distances\n",
    "\n",
    "def rescale_transform(tf, scale):\n",
    "    \"\"\"Rescale a 4x4 homogenous transform matrix by some factor\n",
    "    \n",
    "    Args:\n",
    "        tf (4x4 np.array or python list): homogenous transform matrix to be rescaled\n",
    "        scale: amount to rescale the tf by, e.g. scale=10 will change unit from cm to mm\n",
    "        \n",
    "    Returns:\n",
    "        (4x4 np.array) rescaled transform\n",
    "        \n",
    "    \"\"\"\n",
    "    new_tf = np.array([\n",
    "        [tf[0][0], tf[0][1], tf[0][2], tf[0][3]*scale],\n",
    "        [tf[1][0], tf[1][1], tf[1][2], tf[1][3]*scale],\n",
    "        [tf[2][0], tf[2][1], tf[2][2], tf[2][3]*scale],\n",
    "        [tf[3][0], tf[3][1], tf[3][2], tf[3][3]],\n",
    "    ])\n",
    "\n",
    "    return new_tf\n",
    "\n",
    "def read_transforms_from_file(file_path):\n",
    "    \"\"\"Read in a list of 4x4 homogenous transforms from a csv file\n",
    "    \n",
    "    csv file should be in the format:\n",
    "    Aa, Ab, Ac, Ad, Ae, Af, Ag, Ah, Ai, Aj, Ak, Al, Am, An, Ao, Ap\n",
    "    \n",
    "    where:\n",
    "    \n",
    "         |  Aa, Ab, Ac, Ad  |\n",
    "    tf = |  Ae, Af, Ag, Ah  |\n",
    "         |  Ai, Aj, Ak, Al  |\n",
    "         |  Am, An, Ao, Ap  |\n",
    "         \n",
    "    Args:\n",
    "        file_path: the path to the file to read transforms from\n",
    "        \n",
    "    Returns:\n",
    "        (list of 4x4 np.array objects): transforms read from file\n",
    "    \"\"\"\n",
    "    with open(file_path) as f:\n",
    "        csvfile = csv.reader(f)\n",
    "\n",
    "        raw_transforms = []\n",
    "        for line in csvfile:\n",
    "            items = []\n",
    "            for item in line:\n",
    "                if(item != ' '):\n",
    "                    items.append(float(item))\n",
    "            raw_transforms.append(np.reshape(np.array(items), (4,4)))\n",
    "    \n",
    "    # change unit of transforms from meters to mm (to match sensor measurents, which are in mm)\n",
    "    transforms = [rescale_transform(tf, 1000) for tf in raw_transforms]\n",
    "    \n",
    "    return transforms\n",
    "\n",
    "def read_measurements_from_file(file_path):\n",
    "    \"\"\"Read in a list of measurements from a csv file\n",
    "         \n",
    "    Args:\n",
    "        file_path: the path to the file to read measurements from\n",
    "        \n",
    "    Returns:\n",
    "        (list of floats): measurements read from file\n",
    "    \"\"\"\n",
    "    with open(file_path) as f:\n",
    "        csvfile = csv.reader(f)\n",
    "\n",
    "        data = []\n",
    "        for line in csvfile:\n",
    "            data.append([float(x) for x in line[1:]])\n",
    "\n",
    "        data = np.array(data)\n",
    "    measurements = np.average(data, axis=1)\n",
    "    \n",
    "    return measurements\n",
    "\n",
    "def split_transforms(transforms):\n",
    "    \"\"\"Split a list of homogenous transforms into affine A and translate t components\n",
    "    \n",
    "    Args:\n",
    "        transforms: a list of 4x4 np.array transforms to split\n",
    "        \n",
    "    Returns:\n",
    "        (tuple) (As (list of 3x3 np.arrays), ts (list of length 3 np.arrays)): split transforms\n",
    "    \"\"\"\n",
    "    As = []\n",
    "    ts = []\n",
    "    for tf in transforms:\n",
    "        As.append(\n",
    "            np.array([\n",
    "                [tf[0][0], tf[0][1], tf[0][2]],\n",
    "                [tf[1][0], tf[1][1], tf[1][2]],\n",
    "                [tf[2][0], tf[2][1], tf[2][2]]\n",
    "            ])\n",
    "        )\n",
    "        ts.append(\n",
    "            np.array([tf[0][3], tf[1][3], tf[2][3]])\n",
    "        )\n",
    "        \n",
    "    return (As, ts)\n",
    "\n",
    "def pp_gams(var):\n",
    "    \"\"\"pretty prints a variable that's been pulled from gams\n",
    "    \n",
    "    Args:\n",
    "        var: a parameter or variable that's been pulled from gams\n",
    "        \n",
    "    Returns:\n",
    "        string: an easily readable version of that variable\n",
    "    \"\"\"\n",
    "    string = \"(\"\n",
    "    for x in var:\n",
    "        string += \" \" + str(x[1]) + \",\"\n",
    "    \n",
    "    return string + \" )\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the simulated sensor measurements from a set of motions\n",
    "Next, read in the transforms (robot motions) that were used to run the real world trial 5. We could use some randomly generated set of transforms, but there's no reason to, and by using these, we know that the sensor won't accidentally pass through the plane, because that is impossible in the real world that the motions come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_5_tfs = read_transforms_from_file('data/trial_5/transforms.csv')\n",
    "\n",
    "trial_5_As, trial_5_ts = split_transforms(trial_5_tfs)\n",
    "\n",
    "# p, u, a, d estimates are arbitrary for simulated data. Here I just use rough estimates of\n",
    "# what their true values were when I ran the real experiment\n",
    "p_est = (10, 10, 170)\n",
    "u_est = (-1, 0, 0)\n",
    "a_est = (0, 0, 1)\n",
    "d_est = 187\n",
    "trial_5_sim_ms = gen_sim_trial(trial_5_tfs, p_est, u_est, a_est, d_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we write and test the models on some simulated data, just to confirm that they work in the ideal case. We move on to real-world and noisy simulated data in the \"Evaluation\" section below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares (QCP) Optimization Model - Solve for Sensor Parameters\n",
    "<a id='lstsq_sensor'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gams_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext gams_magic\n"
     ]
    }
   ],
   "source": [
    "%load_ext gams_magic\n",
    "%gams_cleanup -k\n",
    "%gams_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%gams\n",
    "sets\n",
    "    dim \"3D coordinate / vector dimensions\",\n",
    "    obs \"set of observations\",\n",
    "    mat \"entry names for a 3x3 matrix\";\n",
    "\n",
    "parameters\n",
    "    m(obs) \"(m)easurement observed per observation\",\n",
    "    big_A(obs, mat) \"affine transform matrix for robot motion for the given observation\",\n",
    "    t(obs, dim) \"translation component of robot motion for the given observation\"\n",
    "    a(dim) \"a component of plane equation ax+d=0\",\n",
    "    d \"d component of plane equation ax+d=0\";\n",
    "    \n",
    "scalar d;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SETS\"\"\"\n",
    "obs = [str(x) for x in list(range(1, len(trial_5_tfs)+1))] # index for observations\n",
    "mat = ['Aa', 'Ab', 'Ac', 'Ad', 'Ae', 'Af', 'Ag', 'Ah', 'Ai'] # entry names for 3x3 matrix A\n",
    "dim = ['x', 'y', 'z'] # 3D coordinate / vector dimensions\n",
    "\n",
    "%gams_push obs mat dim\n",
    "\n",
    "\"\"\"PARAMETERS\"\"\"\n",
    "m = [(ob, measurement) for (ob, measurement) in zip(obs, trial_5_sim_ms)] # (m)easurement observed per observation\n",
    "\n",
    "big_A = []\n",
    "for ob in obs:\n",
    "    for entry, i in zip(mat, range(len(mat))):\n",
    "        big_A.append((ob, entry, trial_5_As[int(ob)-1].flatten()[i]))\n",
    "        \n",
    "t = []\n",
    "for ob in obs:\n",
    "    for dimens, i in zip(dim, range(len(dim))):\n",
    "        t.append((ob, dimens, trial_5_ts[int(ob)-1][i]))\n",
    "        \n",
    "a = [(dimens, x) for dimens, x in zip(dim, a_est)]\n",
    "d = d_est\n",
    "\n",
    "%gams_push m big_A t a d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solver Status</th>\n",
       "      <th>Model Status</th>\n",
       "      <th>Objective</th>\n",
       "      <th>#equ</th>\n",
       "      <th>#var</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Solver</th>\n",
       "      <th>Solver Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal (1)</td>\n",
       "      <td>OptimalLocal (2)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>QCP</td>\n",
       "      <td>CONOPT</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Solver Status      Model Status  Objective #equ #var Model Type  Solver  \\\n",
       "0    Normal (1)  OptimalLocal (2)        0.0   52   57        QCP  CONOPT   \n",
       "\n",
       "  Solver Time  \n",
       "0       0.005  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%gams\n",
    "option limrow=0, limcol=0;\n",
    "option solprint=off;\n",
    "\n",
    "variables\n",
    "    p(dim) \"position of sensor in 3D space\",\n",
    "    u(dim) \"heading vector denoting orientation of sensor in 3D space (unit length)\",\n",
    "    loss \"objective\",\n",
    "    loss_term(obs) \"loss over one specific observation\";\n",
    "    \n",
    "equations\n",
    "    loss_fn \"overall loss function (objective is to minimize)\",\n",
    "    def_loss_term(obs) \"define one loss term at a time\",\n",
    "    u_unit \"constrain u to be unit length\";\n",
    "    \n",
    "loss_fn..\n",
    "    loss =e= sum(obs, sqr(loss_term(obs)));\n",
    "\n",
    "def_loss_term(obs)..\n",
    "    loss_term(obs) =e=\n",
    "        p(\"x\") * (a(\"x\")*big_A(obs, \"Aa\") + a(\"y\")*big_A(obs, \"Ad\") + a(\"z\")*big_A(obs, \"Ag\"))\n",
    "        + p(\"y\") * (a(\"x\")*big_A(obs, \"Ab\") + a(\"y\")*big_A(obs, \"Ae\") + a(\"z\")*big_A(obs, \"Ah\"))\n",
    "        + p(\"z\") * (a(\"x\")*big_A(obs, \"Ac\") + a(\"y\")*big_A(obs, \"Af\") + a(\"z\")*big_A(obs, \"Ai\"))\n",
    "        + m(obs) * u(\"x\") * (a(\"x\")*big_A(obs, \"Aa\") + a(\"y\")*big_A(obs, \"Ad\") + a(\"z\")*big_A(obs, \"Ag\"))\n",
    "        + m(obs) * u(\"y\") * (a(\"x\")*big_A(obs, \"Ab\") + a(\"y\")*big_A(obs, \"Ae\") + a(\"z\")*big_A(obs, \"Ah\"))\n",
    "        + m(obs) * u(\"z\") * (a(\"x\")*big_A(obs, \"Ac\") + a(\"y\")*big_A(obs, \"Af\") + a(\"z\")*big_A(obs, \"Ai\"))\n",
    "        + d\n",
    "        + sum(dim, a(dim)*t(obs, dim));\n",
    "        \n",
    "u_unit..\n",
    "    sum(dim, sqr(u(dim))) =e= 1;\n",
    "\n",
    "u.l(dim) = sqrt(1/3);\n",
    "    \n",
    "model lstsq /loss_fn, def_loss_term, u_unit/;\n",
    "solve lstsq using qcp minimizing loss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p ( 9.9999999550593, 9.999999998487382, 169.9999999248231, )\n",
      "u ( -0.9999999998051181, -7.268655626432152e-11, 2.8610275954988265e-10, )\n"
     ]
    }
   ],
   "source": [
    "%gams_pull p u\n",
    "print(\"p\", pp_gams(p))\n",
    "print(\"u\", pp_gams(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares (QCP) Optimization Model - Solve for Plane Parameters\n",
    "<a id='lstsq_plane'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gams_cleanup -k\n",
    "%gams_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%gams\n",
    "sets\n",
    "    dim \"3D coordinate / vector dimensions\",\n",
    "    obs \"set of observations\",\n",
    "    mat \"entry names for a 3x3 matrix\";\n",
    "\n",
    "parameters\n",
    "    m(obs) \"(m)easurement observed per observation\",\n",
    "    big_A(obs, mat) \"affine transform matrix for robot motion for the given observation\",\n",
    "    t(obs, dim) \"translation component of robot motion for the given observation\"\n",
    "    p(dim) \"position of sensor on robot\",\n",
    "    u(dim) \"heading vector denoting the orientation of the sensor on the robot\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SETS\"\"\"\n",
    "obs = [str(x) for x in list(range(1, len(trial_5_tfs)+1))] # index for observations\n",
    "mat = ['Aa', 'Ab', 'Ac', 'Ad', 'Ae', 'Af', 'Ag', 'Ah', 'Ai'] # entry names for 3x3 matrix A\n",
    "dim = ['x', 'y', 'z'] # 3D coordinate / vector dimensions\n",
    "\n",
    "%gams_push obs mat dim\n",
    "\n",
    "\"\"\"PARAMETERS\"\"\"\n",
    "m = [(ob, measurement) for (ob, measurement) in zip(obs, trial_5_sim_ms)] # (m)easurement observed per observation\n",
    "\n",
    "big_A = []\n",
    "for ob in obs:\n",
    "    for entry, i in zip(mat, range(len(mat))):\n",
    "        big_A.append((ob, entry, trial_5_As[int(ob)-1].flatten()[i]))\n",
    "        \n",
    "t = []\n",
    "for ob in obs:\n",
    "    for dimens, i in zip(dim, range(len(dim))):\n",
    "        t.append((ob, dimens, trial_5_ts[int(ob)-1][i]))\n",
    "        \n",
    "p = [(dimens, x) for dimens, x in zip(dim, p_est)]\n",
    "u = [(dimens, x) for dimens, x in zip(dim, u_est)]\n",
    "\n",
    "%gams_push m big_A t p u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solver Status</th>\n",
       "      <th>Model Status</th>\n",
       "      <th>Objective</th>\n",
       "      <th>#equ</th>\n",
       "      <th>#var</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Solver</th>\n",
       "      <th>Solver Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal (1)</td>\n",
       "      <td>OptimalLocal (2)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>55</td>\n",
       "      <td>QCP</td>\n",
       "      <td>CONOPT</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Solver Status      Model Status  Objective #equ #var Model Type  Solver  \\\n",
       "0    Normal (1)  OptimalLocal (2)        0.0   52   55        QCP  CONOPT   \n",
       "\n",
       "  Solver Time  \n",
       "0       0.002  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%gams\n",
    "option limrow=0, limcol=0;\n",
    "option solprint=off;\n",
    "\n",
    "variables\n",
    "    a(dim) \"a component of plane equation ax+d=0\",\n",
    "    d \"d component of plane equation ax+d=0\",\n",
    "    loss \"objective\",\n",
    "    loss_term(obs) \"loss over one specific observation\";\n",
    "    \n",
    "equations\n",
    "    loss_fn \"overall loss function (objective is to minimize)\",\n",
    "    def_loss_term(obs) \"define one loss term at a time\"\n",
    "    a_unit \"constrain a to be unit length\";\n",
    "    \n",
    "loss_fn..\n",
    "    loss =e= sum(obs, sqr(loss_term(obs)));\n",
    "\n",
    "def_loss_term(obs)..\n",
    "    loss_term(obs) =e=\n",
    "        p(\"x\") * (a(\"x\")*big_A(obs, \"Aa\") + a(\"y\")*big_A(obs, \"Ad\") + a(\"z\")*big_A(obs, \"Ag\"))\n",
    "        + p(\"y\") * (a(\"x\")*big_A(obs, \"Ab\") + a(\"y\")*big_A(obs, \"Ae\") + a(\"z\")*big_A(obs, \"Ah\"))\n",
    "        + p(\"z\") * (a(\"x\")*big_A(obs, \"Ac\") + a(\"y\")*big_A(obs, \"Af\") + a(\"z\")*big_A(obs, \"Ai\"))\n",
    "        + m(obs) * u(\"x\") * (a(\"x\")*big_A(obs, \"Aa\") + a(\"y\")*big_A(obs, \"Ad\") + a(\"z\")*big_A(obs, \"Ag\"))\n",
    "        + m(obs) * u(\"y\") * (a(\"x\")*big_A(obs, \"Ab\") + a(\"y\")*big_A(obs, \"Ae\") + a(\"z\")*big_A(obs, \"Ah\"))\n",
    "        + m(obs) * u(\"z\") * (a(\"x\")*big_A(obs, \"Ac\") + a(\"y\")*big_A(obs, \"Af\") + a(\"z\")*big_A(obs, \"Ai\"))\n",
    "        + d\n",
    "        + sum(dim, a(dim)*t(obs, dim));\n",
    "\n",
    "a_unit..\n",
    "    sum(dim, sqr(a(dim))) =e= 1;\n",
    "    \n",
    "a.l(dim) = sqrt(1/3);\n",
    "\n",
    "model lstsq /loss_fn, def_loss_term, a_unit/;\n",
    "solve lstsq using qcp minimizing loss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a ( 5.077995606014033e-19, -9.858388584834043e-18, 1.0000000168488792, )\n",
      "d (187.00000315074044, 5e-324, -inf, inf, 1.0)\n"
     ]
    }
   ],
   "source": [
    "%gams_pull a d\n",
    "print(\"a\", pp_gams(a))\n",
    "print(\"d\", d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bilinear'></a>\n",
    "## Bilinear (NLP) Optimization Model - Solve for Plane and Sensor Parameters Simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gams_cleanup -k\n",
    "%gams_reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push data to GAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%gams\n",
    "sets\n",
    "    dim \"3D coordinate / vector dimensions\",\n",
    "    obs \"set of observations\",\n",
    "    mat \"entry names for a 3x3 matrix\";\n",
    "\n",
    "parameters\n",
    "    m(obs) \"(m)easurement observed per observation\",\n",
    "    big_A(obs, mat) \"affine transform matrix for robot motion for the given observation\",\n",
    "    t(obs, dim) \"translation component of robot motion for the given observation\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SETS\"\"\"\n",
    "obs = [str(x) for x in list(range(1, len(trial_5_tfs)+1))] # index for observations\n",
    "mat = ['Aa', 'Ab', 'Ac', 'Ad', 'Ae', 'Af', 'Ag', 'Ah', 'Ai'] # entry names for 3x3 matrix A\n",
    "dim = ['x', 'y', 'z'] # 3D coordinate / vector dimensions\n",
    "\n",
    "%gams_push obs mat dim\n",
    "\n",
    "\"\"\"PARAMETERS\"\"\"\n",
    "m = [(ob, measurement) for (ob, measurement) in zip(obs, trial_5_sim_ms)] # (m)easurement observed per observation\n",
    "\n",
    "big_A = []\n",
    "for ob in obs:\n",
    "    for entry, i in zip(mat, range(len(mat))):\n",
    "        big_A.append((ob, entry, trial_5_As[int(ob)-1].flatten()[i]))\n",
    "        \n",
    "t = []\n",
    "for ob in obs:\n",
    "    for dimens, i in zip(dim, range(len(dim))):\n",
    "        t.append((ob, dimens, trial_5_ts[int(ob)-1][i]))\n",
    "        \n",
    "%gams_push m big_A t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solver Status</th>\n",
       "      <th>Model Status</th>\n",
       "      <th>Objective</th>\n",
       "      <th>#equ</th>\n",
       "      <th>#var</th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Solver</th>\n",
       "      <th>Solver Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal (1)</td>\n",
       "      <td>OptimalLocal (2)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "      <td>NLP</td>\n",
       "      <td>CONOPT</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Solver Status      Model Status  Objective #equ #var Model Type  Solver  \\\n",
       "0    Normal (1)  OptimalLocal (2)        0.0   53   61        NLP  CONOPT   \n",
       "\n",
       "  Solver Time  \n",
       "0       0.015  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%gams\n",
    "option limrow=0, limcol=0;\n",
    "option solprint=off;\n",
    "\n",
    "variables\n",
    "    p(dim) \"position of sensor in 3D space\",\n",
    "    u(dim) \"heading vector denoting orientation of sensor in 3D space (unit length)\",\n",
    "    a(dim) \"a component of plane equation ax+d=0\",\n",
    "    d \"d component of plane equation ax+d=0\",\n",
    "    loss \"objective\",\n",
    "    loss_term(obs) \"loss over one specific observation\";\n",
    "\n",
    "equations\n",
    "    loss_fn \"overall loss function (objective is to minimize)\",\n",
    "    def_loss_term(obs) \"define one loss term at a time\",\n",
    "    u_unit \"constrain u to be a unit vector\",\n",
    "    a_unit \"constrain a to be a unit vector\";\n",
    "\n",
    "loss_fn..\n",
    "    loss =e= sum(obs, sqr(loss_term(obs)));\n",
    "\n",
    "def_loss_term(obs)..\n",
    "    loss_term(obs) =e=\n",
    "        p(\"x\") * (a(\"x\")*big_A(obs, \"Aa\") + a(\"y\")*big_A(obs, \"Ad\") + a(\"z\")*big_A(obs, \"Ag\"))\n",
    "        + p(\"y\") * (a(\"x\")*big_A(obs, \"Ab\") + a(\"y\")*big_A(obs, \"Ae\") + a(\"z\")*big_A(obs, \"Ah\"))\n",
    "        + p(\"z\") * (a(\"x\")*big_A(obs, \"Ac\") + a(\"y\")*big_A(obs, \"Af\") + a(\"z\")*big_A(obs, \"Ai\"))\n",
    "        + m(obs) * u(\"x\") * (a(\"x\")*big_A(obs, \"Aa\") + a(\"y\")*big_A(obs, \"Ad\") + a(\"z\")*big_A(obs, \"Ag\"))\n",
    "        + m(obs) * u(\"y\") * (a(\"x\")*big_A(obs, \"Ab\") + a(\"y\")*big_A(obs, \"Ae\") + a(\"z\")*big_A(obs, \"Ah\"))\n",
    "        + m(obs) * u(\"z\") * (a(\"x\")*big_A(obs, \"Ac\") + a(\"y\")*big_A(obs, \"Af\") + a(\"z\")*big_A(obs, \"Ai\"))\n",
    "        + d\n",
    "        + sum(dim, a(dim)*t(obs, dim));\n",
    "\n",
    "u_unit..\n",
    "    sqrt(sum(dim, sqr(u(dim)))) =e= 1;\n",
    "\n",
    "a_unit..\n",
    "    sqrt(sum(dim, sqr(a(dim)))) =e= 1;\n",
    "\n",
    "* can fix a and d here\n",
    "\n",
    "p.l(\"x\") = 15;\n",
    "p.l(\"y\") = 10;\n",
    "p.l(\"z\") = 170;\n",
    "u.l(\"x\") = -1;\n",
    "u.l(\"y\") = 0;\n",
    "u.l(\"z\") = 0;\n",
    "a.l(\"x\") = 0;\n",
    "a.l(\"y\") = 0;\n",
    "a.l(\"z\") = 1;\n",
    "d.l = 187;\n",
    "\n",
    "model lstsq /all/;\n",
    "solve lstsq using nlp minimizing loss;\n",
    "display p.l;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p [('x', 10.00000002056135, 5e-324, -inf, inf, 1.0), ('y', 10.000000007579754, 5e-324, -inf, inf, 1.0), ('z', 170.00000009588013, 1.132690821526238e-11, -inf, inf, 1.0)]\n",
      "u [('x', -1.0000000002410905, 0.0, -inf, inf, 1.0), ('y', 9.39524010852831e-11, -2.1371354181899987e-09, -inf, inf, 1.0), ('z', -3.798504929524227e-10, 4.487330463066106e-09, -inf, inf, 1.0)]\n",
      "a [('x', 8.850161169310243e-11, -2.1383507292460108e-08, -inf, inf, 1.0), ('y', 9.726327430859958e-12, 2.740366505866235e-09, -inf, inf, 1.0), ('z', 1.0000000000296747, 0.0, -inf, inf, 1.0)]\n",
      "d [(186.99999997149033, -3.291233952040784e-11, -inf, inf, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "%gams_pull p loss u a d loss_term\n",
    "print(\"p\", p)\n",
    "print(\"u\", u)\n",
    "print(\"a\", a)\n",
    "print(\"d\", d)\n",
    "# print(\"loss\", loss)\n",
    "# print(\"loss term\", loss_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Alternating Least Squares (QCP) Optimization Model\n",
    "\n",
    "The bilinear case of our model has something special about it: if you hold any one set of unknowns (either the plane parameters or sensor parameters) constant, it becomes a least squares problem - either the [unknown plane version](#lstsq_plane) or [unknown sensor version](#lstsq_sensor) described above. We could exploit this, and alternate between the two least squares problems, using the solution from one model to fix the parameters in the next. This way, we would never have to touch NLP! (Although, in a way, we would still be doing NLP, just more manually, using two QCPs, I think)\n",
    "\n",
    "At least, in theory. I messed around this for a while and never got it working. I haven't found great resources for this online - most are talking about the matrix factorization problem, which may be equivalent, but reading about it doesn't help. I think the problem is that our problems aren't plain least squares because of the unit vector constraints, so they're not gauranteed to converge when you alternate.\n",
    "\n",
    "I've removed my work since this document is already long and there are more interesting things to focus on. Plus, [the NLP model above](#bilinear) seems to be pretty robust, and fast enough, since we're never going to be solving problems with more than ~50 terms, and speed is not crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Sensitivity Analysis and Cross Validation\n",
    "<a id='evaluation'></a>\n",
    "\n",
    "We evaluate our models' performance in two ways:\n",
    "1. Use simulated data for which we know the ground truth, and test for solution accuracy given some known noise model for the sensor measurements. This may not translate to the real world, in which the noise model for the sensor is not exactly known.\n",
    "2. Use real data gathered from a sensor attached to a robot, and test for solution *precision*, not accuracy, since ground truth is not exactly known. Find the \"cross-trial\" precision by using all measurements from two separate trials which have different plane positions and motions, but the same sensor position, and comparing their solved position. In reality, this position should be the same for both trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some helper functions to help us with evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gams_to_list(gams_param):\n",
    "    \"\"\"Convert a gams parameter's .l values to a python list\n",
    "    \n",
    "    Args:\n",
    "        gams_param: gams style parameter to be converted\n",
    "        \n",
    "    Returns:\n",
    "        (list): the parameter's .l values as a list\n",
    "    \"\"\"\n",
    "    \n",
    "    return [x[1] for x in gams_param]\n",
    "\n",
    "def l2_distance(p1, p2):\n",
    "    \"\"\"Get l2 distance between point p1 and point p2\n",
    "    \n",
    "    Args:\n",
    "        p1: first point\n",
    "        p2: second point\n",
    "        \n",
    "    Returns:\n",
    "        (float): l2 distance between point 1 and point 2\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\"Get angle between two vectors v1 and v2\n",
    "    \n",
    "    \"\"\"\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    angle = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Models via Sensitivity Analysis on Simulated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to re-run some previous cells to get the correct gams model loaded up. To avoid copy-pasting code (because I can't figure out how to put gams code inside a function) we do this programatically with some JavaScript jupyter notebook magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.execute_cells([8, 9, 10, 11]) // run cells 8, 9, 10, 11\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.execute_cells([8, 9, 10, 11]) // run cells 8, 9, 10, 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loop runs the least squares optimization 1000 times, with different noise in the data ($\\textbf{a}$, $d$, and $m_i$) each time. We then record the error in the solution and plot the distribution of error for both the linear least squares (QCP) problem, and the bilinear (NLP) problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error in solved sensor position: 45.149248663885494 mm\n",
      "Average error in solved sensor orientation: 6.369926449011052  degrees\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0) # for re-producability\n",
    "\n",
    "p_errors = []\n",
    "u_errors = []\n",
    "for _ in range(100):\n",
    "    d = d_est + np.random.normal(0, 5) # add noise to the d plane parameter estimate\n",
    "    \n",
    "    rand_a = [x + np.random.normal(0, 0.05) for x in a_est] # add noise to the a plane param. est.\n",
    "    a_noisy = np.array(rand_a) / np.linalg.norm(np.array(rand_a)) # normalize the random a parameter\n",
    "    a = [(dimens, x) for dimens, x in zip(dim, a_noisy)]\n",
    "    \n",
    "    trial_5_sim_ms_noisy = [x + np.random.normal(0, 5) for x in trial_5_sim_ms] # add noise to measurements\n",
    "    m = [(ob, measurement) for (ob, measurement) in zip(obs, trial_5_sim_ms_noisy)]\n",
    "    \n",
    "    %gams_push m a d\n",
    "    %gams model lstsq /all/;\n",
    "    %gams solve lstsq using qcp minimizing loss;\n",
    "    %gams_pull p u\n",
    "    p_errors.append(l2_distance(gams_to_list(p), p_est))\n",
    "    u_errors.append(angle_between(gams_to_list(u), u_est))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].hist(p_errors)\n",
    "ax[0].set_xlabel(\"Error in solved position (mm)\")\n",
    "ax[0].set_ylabel(\"# occurences\")\n",
    "ax[1].hist([np.degrees(x) for x in u_errors])\n",
    "ax[1].set_xlabel(\"Error in solved orientation (degrees)\")\n",
    "fig.suptitle(\"Solution Error with Simulated Data - Least Squares (QCP) Model\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Average error in solved sensor position:\", sum(p_errors) / len(p_errors), \"mm\")\n",
    "print(\"Average error in solved sensor orientation:\", np.degrees(sum(u_errors) / len(u_errors)), \" degrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.execute_cells([20, 22, 23, 24]) // run cells 20, 22, 23, 24\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.execute_cells([20, 22, 23, 24]) // run cells 20, 22, 23, 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error in solved sensor position: 20.805282417560747 mm\n",
      "Average error in solved sensor orientation: 3.6697371956282376  degrees\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0) # for re-producability\n",
    "\n",
    "p_errors = []\n",
    "u_errors = []\n",
    "for _ in range(100):\n",
    "    d_gms_est = d_est + np.random.normal(0, 5) # add noise to the d plane parameter estimate\n",
    "    \n",
    "    rand_a = [x + np.random.normal(0, 0.05) for x in a_est] # add noise to the a plane param. est.\n",
    "    a_noisy = np.array(rand_a) / np.linalg.norm(np.array(rand_a)) # normalize the random a parameter\n",
    "    a_x_est, a_y_est, a_z_est = a_noisy\n",
    "    \n",
    "    trial_5_sim_ms_noisy = [x + np.random.normal(0, 5) for x in trial_5_sim_ms] # add noise to measurements\n",
    "    m = [(ob, measurement) for (ob, measurement) in zip(obs, trial_5_sim_ms_noisy)]\n",
    "    \n",
    "    %gams scalar a_x_est, a_y_est, a_z_est, d_gms_est;\n",
    "    \n",
    "    %gams_push m a_x_est a_y_est a_z_est d_gms_est\n",
    "    \n",
    "    %gams a.l(\"x\") = a_x_est;\n",
    "    %gams a.l(\"y\") = a_y_est;\n",
    "    %gams a.l(\"z\") = a_z_est;\n",
    "    %gams d.l = d_gms_est;\n",
    "    %gams model lstsq /all/;\n",
    "    %gams solve lstsq using nlp minimizing loss;\n",
    "    \n",
    "    %gams_pull p u\n",
    "    \n",
    "    p_errors.append(l2_distance(gams_to_list(p), p_est))\n",
    "    u_errors.append(angle_between(gams_to_list(u), u_est))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].hist(p_errors)\n",
    "ax[0].set_xlabel(\"Error in solved position (mm)\")\n",
    "ax[0].set_ylabel(\"# occurences\")\n",
    "ax[1].hist([np.degrees(x) for x in u_errors])\n",
    "ax[1].set_xlabel(\"Error in solved orientation (degrees)\")\n",
    "fig.suptitle(\"Solution Error with Simulated Data - Bilinear (NLP) Model\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Average error in solved sensor position:\", sum(p_errors) / len(p_errors), \"mm\")\n",
    "print(\"Average error in solved sensor orientation:\", np.degrees(sum(u_errors) / len(u_errors)), \" degrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bilinear NLP model seems to be less sensitive to noise by a significant amount - the average error is half as much as the least squares QCP model. This is not surprising - because the bilinear NLP model is able to adjust the plane parameters, it is less thrown off by variations in the plane estimates. Meanwhile, the linear model has to trust the plane parameters that we give it. The thing we give up when we use the NLP model is a guarantee of finding a global minima, and, theoretically, some speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Models via Cross Validation with Real Data\n",
    "\n",
    "Sensitivity analysis on simulated data will give us a good idea of how sensitive our solution is to noise, but it assumes some noise model (we used zero-centered gaussian above) which is probably not true to life. To assess how well our models work to enable calibration in the real world, we can perform cross-validation.\n",
    "\n",
    "We have data from four real world trials, which use four sets of motions, two different planes, and two sensor positions. We are able to solve for all four trials, using both methods, and compare the solved sensor positions. In reality, between certain pairs of trials, the sensor did not move, so we can use the distance between the solved position of those trials as a measure of the precision of our solution.\n",
    "\n",
    "Ideally, we would have a lot more than two sample points. I'm working on automating robot motions so that we can more easily gather more data, but that data is not available yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.execute_cells([8, 9, 10, 11]) // run cells 8, 9, 10, 11\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.execute_cells([8, 9, 10, 11]) // run cells 8, 9, 10, 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_ps = []\n",
    "linear_us = []\n",
    "bilinear_ps = []\n",
    "bilinear_us = []\n",
    "\n",
    "for trial_name in ['trial_5', 'trial_6', 'trial_7', 'trial_8']:\n",
    "    transforms = read_transforms_from_file(f'data/{trial_name}/transforms.csv')\n",
    "    As, ts = split_transforms(transforms)\n",
    "    measurements = read_measurements_from_file(f'data/{trial_name}/measurements.csv')\n",
    "    \n",
    "    m = [(ob, measurement) for (ob, measurement) in zip(obs, measurements)]\n",
    "\n",
    "    big_A = []\n",
    "    for ob in obs:\n",
    "        for entry, i in zip(mat, range(len(mat))):\n",
    "            big_A.append((ob, entry, As[int(ob)-1].flatten()[i]))\n",
    "\n",
    "    t = []\n",
    "    for ob in obs:\n",
    "        for dimens, i in zip(dim, range(len(dim))):\n",
    "            t.append((ob, dimens, ts[int(ob)-1][i]))\n",
    "            \n",
    "    # set a and d plane parameter estimates depending on the trial\n",
    "    if (trial_name == 'trial_5' or trial_name == 'trial_8'):\n",
    "        a_est = (0, 0, 1)\n",
    "        d_est = 187\n",
    "    elif (trial_name == 'trial_6' or trial_name == 'trial_7'):\n",
    "        a_est = (1, 0, 0)\n",
    "        d_est = -900\n",
    "        \n",
    "    a = [(dimens, x) for dimens, x in zip(dim, a_est)]\n",
    "    d = d_est\n",
    "    \n",
    "    %gams_push big_A t a d m\n",
    "    %gams model lstsq /all/;\n",
    "    %gams solve lstsq using qcp minimizing loss;\n",
    "    %gams_pull p u\n",
    "    \n",
    "    linear_ps.append(p)\n",
    "    linear_us.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.execute_cells([20, 22, 23, 24]) // run cells 8, 9, 10, 11\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.execute_cells([20, 22, 23, 24]) // run cells 8, 9, 10, 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----QCP Cross-Validated Errors-----\n",
      "Trial 5 vs. Trial 8: 48.64mm / 1.64 degrees\n",
      "Trial 6 vs. Trial 7: 49.06mm / 1.44 degrees\n",
      "\n",
      "-----NLP Cross-Validated Errors-----\n",
      "Trial 5 vs. Trial 8: 61.66mm / 1.92 degrees\n",
      "Trial 6 vs. Trial 7: 46.99mm / 1.70 degrees\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for trial_name in ['trial_5', 'trial_6', 'trial_7', 'trial_8']:\n",
    "    transforms = read_transforms_from_file(f'data/{trial_name}/transforms.csv')\n",
    "    As, ts = split_transforms(transforms)\n",
    "    measurements = read_measurements_from_file(f'data/{trial_name}/measurements.csv')\n",
    "    \n",
    "    m = [(ob, measurement) for (ob, measurement) in zip(obs, measurements)]\n",
    "\n",
    "    big_A = []\n",
    "    for ob in obs:\n",
    "        for entry, i in zip(mat, range(len(mat))):\n",
    "            big_A.append((ob, entry, As[int(ob)-1].flatten()[i]))\n",
    "\n",
    "    t = []\n",
    "    for ob in obs:\n",
    "        for dimens, i in zip(dim, range(len(dim))):\n",
    "            t.append((ob, dimens, ts[int(ob)-1][i]))\n",
    "            \n",
    "    # set a and d plane parameter estimates depending on the trial\n",
    "    if (trial_name == 'trial_5' or trial_name == 'trial_8'):\n",
    "        a_est = (0, 0, 1)\n",
    "        d_est = 187\n",
    "    elif (trial_name == 'trial_6' or trial_name == 'trial_7'):\n",
    "        a_est = (1, 0, 0)\n",
    "        d_est = -900\n",
    "        \n",
    "    a_x_est, a_y_est, a_z_est = a_est\n",
    "    d_gms_est = d_est\n",
    "    \n",
    "    %gams scalar a_x_est, a_y_est, a_z_est, d_gms_est;\n",
    "    \n",
    "    %gams_push big_A t m a_x_est a_y_est a_z_est d_gms_est\n",
    "    \n",
    "    %gams a.l(\"x\") = a_x_est;\n",
    "    %gams a.l(\"y\") = a_y_est;\n",
    "    %gams a.l(\"z\") = a_z_est;\n",
    "    %gams d.l = d_gms_est;    \n",
    "    %gams model lstsq /all/;\n",
    "    %gams solve lstsq using nlp minimizing loss;\n",
    "    %gams_pull p u\n",
    "    \n",
    "    bilinear_ps.append(p)\n",
    "    bilinear_us.append(u)\n",
    "    \n",
    "print(\"-----QCP Cross-Validated Errors-----\")\n",
    "print(\"Trial 5 vs. Trial 8:\", f\"{l2_distance(gams_to_list(linear_ps[0]), gams_to_list(linear_ps[3])):.2f}mm / {np.degrees(angle_between(gams_to_list(linear_us[0]), gams_to_list(linear_us[3]))):.2f} degrees\")\n",
    "print(\"Trial 6 vs. Trial 7:\", f\"{l2_distance(gams_to_list(linear_ps[1]), gams_to_list(linear_ps[2])):.2f}mm / {np.degrees(angle_between(gams_to_list(linear_us[1]), gams_to_list(linear_us[2]))):.2f} degrees\")\n",
    "print()\n",
    "\n",
    "print(\"-----NLP Cross-Validated Errors-----\")\n",
    "print(\"Trial 5 vs. Trial 8:\", f\"{l2_distance(gams_to_list(bilinear_ps[0]), gams_to_list(bilinear_ps[3])):.2f}mm / {np.degrees(angle_between(gams_to_list(bilinear_us[0]), gams_to_list(bilinear_us[3]))):.2f} degrees\")\n",
    "print(\"Trial 6 vs. Trial 7:\", f\"{l2_distance(gams_to_list(bilinear_ps[1]), gams_to_list(bilinear_ps[2])):.2f}mm / {np.degrees(angle_between(gams_to_list(bilinear_us[1]), gams_to_list(bilinear_us[2]))):.2f} degrees\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On our real-world cross validation test, the NLP model actually performs slightly worse, which is not what I expected.\n",
    "\n",
    "One easy explanation is that our sample size for cross validation is too small, and the QCP model is getting lucky. Maybe given enough samples, the NLP model would come out on top. Another explanation is that the estimates for the plane, which the QCP model trusts entirely and has no ability to modify, are pretty good. Maybe the NLP model is being too liberal with it's ability to move the plane. I describe a way to address this in [Future Work](#future_work)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "<a id='future_work'></a>\n",
    "## Future Work\n",
    "Some ideas for future directions for the project, modeling-wise:\n",
    "- **Punish the NLP model for adjusting plane parameters:** we could create some variable which tracks how much the plane parameters have moved from the initial estimate, and add them to the objective function, with some weight. We could then try many different values of that weighting variable to find the sweet spot between the bilinear and least squares model which allows the plane to move, but not too much.\n",
    "- **Experiment with different loss functions:** we only used an l2-norm loss function in our models, but other loss functions, such as the huber or l1-norm may give better results, especially on real-world data which may have strong outliers, which the l2-norm is sensitive to.\n",
    "- **Eliminate the need for initial estimates:** without any initial estimates, the bilinear NLP model fails to solve. We could, however, try searching many random initial estimates, and we might eventually hit one which does solve. If we hit many that solve, we can take the one with the lowest loss. This is made possible by the fact that we have a finite search space: the sensor can only be so far out on the robot.\n",
    "\n",
    "## Takeaways\n",
    "\n",
    "TODOTODOTODO\n",
    "\n",
    "Since this is part of an ongoing project, I'd love your feedback on ways to improve the solving, with a focus on accuracy over speed. If you're not able to on canvas you can shoot me an email if you have the chance, sifferman@wisc.edu.\n",
    "\n",
    "Thanks for a good semester!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
